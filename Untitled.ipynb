{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea430597-2249-4e08-8eeb-5c8934d982df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_pre\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_pre\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83d51e1-cb15-41e2-883c-5175ddfa37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "data_dir = r\"Data\\test\"  # Replace with your path\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "num_classes = 7\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e416e-39fc-4e7c-b541-365b730bbcc2",
   "metadata": {},
   "source": [
    "### Image Generators for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672732a7-e6b5-45ee-b152-5798631ee9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(preprocess_input_fn):\n",
    "    return ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input_fn,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "def load_data(preprocess_input_fn):\n",
    "    datagen = get_data_generator(preprocess_input_fn)\n",
    "    train = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    val = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=True\n",
    "    )\n",
    "    return train, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa9bb2-517b-40ac-94a1-2a20b5935b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c7e7724-e1f5-4e2f-99e3-409d1c35cf95",
   "metadata": {},
   "source": [
    "### Build Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968d8254-6389-482e-b04b-c0049959376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_model(base_model, preprocess_input_fn, name):\n",
    "    train_gen, val_gen = load_data(preprocess_input_fn)\n",
    "\n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "    history = model.fit(train_gen, epochs=epochs, validation_data=val_gen)\n",
    "\n",
    "    model.save(f\"{name}_rice_model.h5\")\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b53ca-cf40-4210-9f3d-c54a138857dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cd2bc5-f2cb-493d-9072-1bf998c822df",
   "metadata": {},
   "source": [
    "### Train with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77381314-bffb-4bc5-bdba-7c3f60bdfbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5746 images belonging to 7 classes.\n",
      "Found 1432 images belonging to 7 classes.\n",
      "\n",
      "Training: VGG16\n",
      "Epoch 1/10\n",
      "\u001b[1m  5/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:10\u001b[0m 16s/step - accuracy: 0.1437 - loss: 5.8736"
     ]
    }
   ],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "vgg_model, vgg_history = build_transfer_model(vgg_base, vgg_pre, \"VGG16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac1de2-44ac-44e6-be45-57b73ca0902c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcca030f-179a-4f21-9424-17f8d134c783",
   "metadata": {},
   "source": [
    "### Train with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c78f15-fb41-483d-8f23-06d0bce7e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "resnet_model, resnet_history = build_transfer_model(resnet_base, resnet_pre, \"ResNet50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175e146-2d05-4971-a9c0-b34e7deb8042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009c3a03-5a1e-4cf6-a9a7-3c8815ea9435",
   "metadata": {},
   "source": [
    "### Train with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529aff53-152f-4223-82cc-e801a14bc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "mobilenet_model, mobilenet_history = build_transfer_model(mobilenet_base, mobilenet_pre, \"MobileNetV2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
